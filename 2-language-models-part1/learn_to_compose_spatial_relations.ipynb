{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "learn_to_compose_spatial_relations.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/learn_to_compose_spatial_relations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRIXnvl3UttS",
        "colab_type": "text"
      },
      "source": [
        "# How Neural Language Models Learn To Compose?\n",
        "\n",
        "- Composing word sequence (words -> phrases)\n",
        "- Composing different representations (fusion of modalities)\n",
        "\n",
        "**Method:** \n",
        "- Generate descriptions based on their acceptability for each situation.\n",
        "- Train a neural language model. \n",
        "- Reconstruct the spatial templates for any word composition based on the language model.\n",
        "- Show that spatial templates can be learned for unseen word sequences inlcuding unseen single word usages. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4uD6XXUeOUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we are going to need these libraries\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import mstats, spearmanr, pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product, combinations\n",
        "from IPython.core.display import Markdown\n",
        "\n",
        "## library\n",
        "# If you use GPU, selection it first:\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "# Keras library\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Flatten, AveragePooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Masking, Dropout\n",
        "from tensorflow.keras.layers import Input, Lambda, RepeatVector, Reshape\n",
        "from tensorflow.keras.layers import TimeDistributed, Concatenate\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyYTRI3peOU3",
        "colab_type": "text"
      },
      "source": [
        "## Acceptabilities as Representation of Spatial Relations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke1m1TgueOU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spatial templates from human judgments on 10 spatial relations: \n",
        "\"\"\"\n",
        "@article{logan1996computational,\n",
        "  title={A computational analysis of the apprehension of spatial relations.},\n",
        "  author={Logan, Gordon D and Sadler, Daniel D},\n",
        "  year={1996},\n",
        "  publisher={The MIT Press}\n",
        "}\n",
        "\"\"\"\n",
        "#templates = np.load('logan_sadler_1996.npy', allow_pickle=True)[None][0]\n",
        "templates = {\n",
        " 'above': np.array([[7.  , 7.66, 8.1 , 8.61, 8.19, 7.32, 7.66],\n",
        "        [6.69, 6.56, 7.66, 8.55, 7.13, 7.16, 6.88],\n",
        "        [5.63, 6.41, 7.09, 8.53, 7.35, 6.74, 5.53],\n",
        "        [1.94, 2.16, 1.88, 0.  , 1.97, 1.88, 2.  ],\n",
        "        [1.94, 1.78, 1.66, 1.13, 1.63, 2.41, 1.66],\n",
        "        [1.81, 1.94, 1.42, 1.03, 1.5 , 1.84, 1.58],\n",
        "        [1.44, 1.38, 1.34, 1.19, 1.34, 2.08, 1.44]], ),\n",
        " 'below': np.array([[1.5 , 1.66, 1.29, 1.03, 1.33, 1.75, 1.59],\n",
        "        [1.71, 2.09, 1.4 , 1.31, 1.44, 1.66, 1.45],\n",
        "        [1.94, 2.09, 1.65, 1.72, 1.88, 2.39, 2.  ],\n",
        "        [2.16, 2.29, 2.03, 0.  , 2.41, 1.94, 2.  ],\n",
        "        [5.66, 6.31, 6.94, 8.16, 6.94, 6.  , 5.81],\n",
        "        [6.  , 7.09, 7.74, 8.71, 7.78, 7.1 , 6.88],\n",
        "        [7.42, 5.  , 6.88, 8.4 , 7.72, 7.71, 7.53]], ),\n",
        " 'over': np.array([[8.84, 7.65, 8.1 , 8.9 , 7.59, 7.38, 7.1 ],\n",
        "        [6.75, 6.94, 7.19, 8.29, 7.45, 7.32, 8.41],\n",
        "        [5.69, 5.97, 7.07, 8.42, 7.19, 6.38, 5.58],\n",
        "        [1.91, 2.19, 2.09, 0.  , 2.13, 1.94, 2.25],\n",
        "        [2.28, 1.91, 1.71, 1.28, 1.97, 2.09, 2.  ],\n",
        "        [1.69, 2.  , 1.28, 1.45, 2.19, 1.69, 1.66],\n",
        "        [1.52, 1.59, 1.52, 1.2 , 1.28, 1.66, 1.66]], ),\n",
        " 'under': np.array([[1.81, 1.94, 1.38, 1.39, 1.59, 1.72, 1.47],\n",
        "        [1.83, 1.53, 2.03, 1.41, 1.44, 1.63, 1.84],\n",
        "        [1.77, 1.78, 1.63, 1.44, 1.59, 1.68, 2.19],\n",
        "        [2.06, 2.22, 1.91, 0.  , 2.25, 2.39, 2.  ],\n",
        "        [5.71, 5.66, 6.75, 8.23, 6.84, 5.88, 5.84],\n",
        "        [6.59, 7.  , 7.59, 7.45, 7.38, 6.5 , 6.1 ],\n",
        "        [7.22, 7.55, 7.9 , 8.72, 7.78, 7.74, 7.03]], ),\n",
        " 'next_to': np.array([[2.65, 2.06, 2.1 , 2.03, 2.29, 1.94, 1.7 ],\n",
        "        [2.84, 3.32, 3.31, 3.91, 3.35, 3.34, 2.94],\n",
        "        [4.06, 4.75, 5.9 , 6.7 , 6.57, 4.72, 3.87],\n",
        "        [4.52, 6.  , 8.17, 0.  , 8.39, 6.69, 4.88],\n",
        "        [3.56, 4.59, 6.59, 6.19, 5.91, 5.38, 4.13],\n",
        "        [2.94, 3.58, 3.66, 4.06, 4.  , 3.32, 3.06],\n",
        "        [2.37, 2.06, 2.53, 2.31, 1.81, 2.  , 1.69]], ),\n",
        " 'away_from': np.array([[7.38, 7.94, 7.45, 7.74, 7.72, 8.1 , 8.44],\n",
        "        [7.41, 6.84, 5.74, 5.16, 5.69, 6.72, 7.22],\n",
        "        [5.9 , 4.75, 2.94, 2.91, 2.78, 5.13, 6.47],\n",
        "        [5.35, 4.38, 2.13, 0.  , 1.88, 4.58, 6.25],\n",
        "        [6.32, 4.81, 3.09, 2.5 , 3.44, 5.41, 6.45],\n",
        "        [7.28, 6.09, 5.34, 4.97, 5.41, 5.75, 7.66],\n",
        "        [8.1 , 7.5 , 7.58, 7.63, 7.44, 7.83, 8.26]], ),\n",
        " 'near_to': np.array([[1.74, 1.9 , 2.84, 3.16, 2.34, 1.81, 2.13],\n",
        "        [2.61, 3.84, 4.66, 4.97, 4.9 , 3.56, 3.26],\n",
        "        [4.06, 5.56, 7.55, 7.97, 7.29, 4.8 , 3.91],\n",
        "        [4.47, 5.91, 8.52, 0.  , 7.9 , 6.13, 4.63],\n",
        "        [3.47, 4.81, 6.94, 7.56, 7.31, 5.59, 3.63],\n",
        "        [3.25, 4.03, 4.5 , 4.78, 4.41, 3.47, 3.1 ],\n",
        "        [1.84, 2.23, 2.03, 3.06, 2.53, 2.13, 2.  ]], ),\n",
        " 'far_from': np.array([[7.48, 7.94, 7.56, 7.42, 7.38, 7.88, 8.48],\n",
        "        [6.56, 5.78, 5.41, 5.41, 5.19, 5.38, 7.03],\n",
        "        [5.69, 4.03, 2.28, 1.78, 2.84, 4.13, 6.06],\n",
        "        [5.59, 3.44, 1.87, 0.  , 1.66, 4.22, 5.71],\n",
        "        [6.9 , 4.56, 2.28, 1.81, 2.31, 4.09, 6.13],\n",
        "        [7.09, 6.03, 4.88, 5.19, 5.16, 6.  , 7.42],\n",
        "        [7.68, 7.77, 7.58, 7.13, 7.47, 7.78, 8.41]], ),\n",
        " 'left_of': np.array([[6.56, 5.65, 5.28, 2.56, 2.13, 1.88, 1.66],\n",
        "        [7.  , 6.06, 5.39, 2.25, 2.16, 1.53, 1.8 ],\n",
        "        [7.13, 6.52, 6.34, 2.31, 2.47, 1.94, 2.1 ],\n",
        "        [8.35, 7.83, 8.06, 0.  , 1.1 , 1.59, 1.94],\n",
        "        [6.84, 6.39, 6.65, 2.16, 2.03, 2.1 , 1.41],\n",
        "        [6.03, 6.23, 5.63, 2.48, 1.9 , 2.22, 1.59],\n",
        "        [6.16, 5.77, 4.94, 1.9 , 1.94, 1.94, 2.03]], ),\n",
        " 'right_of': np.array([[1.72, 1.97, 1.66, 2.22, 5.5 , 6.45, 6.59],\n",
        "        [1.9 , 2.  , 2.  , 2.28, 5.78, 6.52, 7.06],\n",
        "        [1.33, 1.63, 2.13, 2.39, 6.39, 6.84, 7.03],\n",
        "        [1.09, 1.35, 1.38, 0.  , 8.35, 8.52, 8.71],\n",
        "        [1.69, 1.74, 2.25, 2.09, 6.03, 6.81, 7.5 ],\n",
        "        [1.66, 1.94, 1.81, 2.03, 5.59, 6.72, 6.63],\n",
        "        [1.5 , 1.72, 1.94, 1.87, 5.47, 6.13, 6.44]], )\n",
        "}\n",
        "\n",
        "# min-max normalisation of the template \n",
        "def normalize(x, x_min=None, x_max=None):\n",
        "    if x_min is None:\n",
        "        x_min = x.min() \n",
        "    if x_max is None:\n",
        "        x_max = x.max()\n",
        "    out = (x - x_min) / (x_max - x_min)\n",
        "    out[3,3] = 0\n",
        "    \n",
        "    return out\n",
        "\n",
        "for w in templates:\n",
        "    templates[w] = normalize(templates[w], x_min=1, x_max=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T27b_CTGeOVB",
        "colab_type": "text"
      },
      "source": [
        "### Visualize all generated templates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwyegmreeOVC",
        "colab_type": "code",
        "outputId": "ad607ee8-2ace-40b2-82a3-2d3f39e9bdac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# plotting funciton for any 7x7 template\n",
        "def plot_template(template, title, savefig=False):\n",
        "    landmark = np.zeros([7,7,4])\n",
        "    landmark[3,3] = np.array([0., 0., 1., 1.])\n",
        "    \n",
        "    sizes = template * 500\n",
        "    \n",
        "    points = np.array([\n",
        "        [i, j, sizes[j, i]]\n",
        "        for i in range(7)\n",
        "        for j in range(7)\n",
        "    ])\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.scatter(x=points[:, 0], y=points[:, 1], s=points[:, 2], c=\"black\", marker='o', linewidths=0)\n",
        "    plt.imshow(landmark)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    if savefig:\n",
        "        img_path = \"plots/\" + title.replace(\" \", \"_\") + \".png\"\n",
        "        plt.savefig(img_path, bbox_inches = 'tight', pad_inches = 0)\n",
        "        plt.clf()\n",
        "        return img_path\n",
        "    else:\n",
        "        plt.show()\n",
        "        return \n",
        "\n",
        "plot_template(templates[\"above\"], \"above\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuAShQMi4BKFAyLgEoUDIuAShQP4fDGlDEtNYGaYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN9ch1PaZDtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_situaiton(i, j):\n",
        "    situation = np.zeros([7, 7])\n",
        "    situation[i, j] = 1\n",
        "    return situation\n",
        "\n",
        "# generate images for visualisation\n",
        "ploted_situaitons = [\n",
        "    (\"situ_{0}x{1}\".format(i+1, j+1), plot_template(generate_situaiton(i, j), title=\"situ_{0}x{1}\".format(i+1, j+1), savefig=True))\n",
        "    for i in range(7)\n",
        "    for j in range(7)\n",
        "]\n",
        "\n",
        "#markdown = \"\"\n",
        "#for i in range(0, len(ploted_situaitons), 7):\n",
        "#    titles, imgpaths = zip(*ploted_situaitons[i:i+7])\n",
        "#    markdown += \"| {0} |\\n\".format(\" | \".join(titles))\n",
        "#    markdown += \"|:---:\" * len(titles) + \"|\\n\"\n",
        "#    markdown += \"| {0} |\\n\".format(\" | \".join(map(to_md, imgpaths)))\n",
        "#    markdown += \"\\n\"\n",
        "#    \n",
        "#Markdown(markdown)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBu5ltXGjrd7",
        "colab_type": "text"
      },
      "source": [
        "| situ_1x1 | situ_1x2 | situ_1x3 | situ_1x4 | situ_1x5 | situ_1x6 | situ_1x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_1x7.png?raw=1) |\n",
        "\n",
        "| situ_2x1 | situ_2x2 | situ_2x3 | situ_2x4 | situ_2x5 | situ_2x6 | situ_2x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_2x7.png?raw=1) |\n",
        "\n",
        "| situ_3x1 | situ_3x2 | situ_3x3 | situ_3x4 | situ_3x5 | situ_3x6 | situ_3x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_3x7.png?raw=1) |\n",
        "\n",
        "| situ_4x1 | situ_4x2 | situ_4x3 | situ_4x4 | situ_4x5 | situ_4x6 | situ_4x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_4x7.png?raw=1) |\n",
        "\n",
        "| situ_5x1 | situ_5x2 | situ_5x3 | situ_5x4 | situ_5x5 | situ_5x6 | situ_5x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_5x7.png?raw=1) |\n",
        "\n",
        "| situ_6x1 | situ_6x2 | situ_6x3 | situ_6x4 | situ_6x5 | situ_6x6 | situ_6x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_6x7.png?raw=1) |\n",
        "\n",
        "| situ_7x1 | situ_7x2 | situ_7x3 | situ_7x4 | situ_7x5 | situ_7x6 | situ_7x7 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x1.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x2.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x3.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x4.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x5.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x6.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/situ_7x7.png?raw=1) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUzkPTEpeOU6",
        "colab_type": "text"
      },
      "source": [
        "### Generating Spatial Relations Using Logical Compositions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHckfCUaeOU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating spatial relations based on logical compositions:\n",
        "to_string = {\n",
        "    None:  lambda w:  \"{0}\".format(w),\n",
        "    \"not\": lambda w:  \"not {0}\".format(w),\n",
        "    \"and\": lambda ws: \"{0} and {1}\".format(ws[0], ws[1]),\n",
        "    \"or\":  lambda ws: \"either {0} or {1}\".format(ws[0], ws[1]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edxq6Dt9eOU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How?\n",
        "\n",
        "# Complement as negation of a template\n",
        "def negate(template):\n",
        "    out = 1 - template\n",
        "    # center\n",
        "    out[3,3] = 0\n",
        "\n",
        "    return out\n",
        "\n",
        "# Multiplication as conjunction of two templates\n",
        "def conjunct(template1, template2):\n",
        "    out = template1 * template2\n",
        "    # center\n",
        "    out[3,3] = 0\n",
        "    \n",
        "    return out\n",
        "\n",
        "# Co-multiplication as disjunction of two templates\n",
        "def disjunct(template1, template2):\n",
        "    out = template1 + template2 - template1 * template2\n",
        "    # center\n",
        "    out[3,3] = 0\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-bI6VfeOU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all possible templates\n",
        "new_templates = dict()\n",
        "\n",
        "for w in templates:\n",
        "    # no composition\n",
        "    new_templates[(None, w)] = templates[w]\n",
        "\n",
        "    # negation\n",
        "    new_templates[(\"not\", w)] = negate(templates[w])\n",
        "\n",
        "    \n",
        "for w1, w2 in combinations(templates, 2):\n",
        "    # conjunction\n",
        "    new_templates[(\"and\", (w1, w2))] = conjunct(templates[w1], templates[w2])\n",
        "\n",
        "    # disjunction\n",
        "    new_templates[(\"or\", (w1, w2))] = disjunct(templates[w1], templates[w2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYAXMO4BXwf-",
        "colab_type": "text"
      },
      "source": [
        "#### Plot all possible templates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDD3IOpXh2RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir plots"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0ymOJbwzeOVG",
        "colab_type": "code",
        "outputId": "d6cc1fcb-9258-4ae6-d2e4-b68360afe2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def to_md(path):\n",
        "    return \"![]({0})\".format(path)\n",
        "\n",
        "# generate images for visualisation\n",
        "ploted_images = [\n",
        "    (to_string[key[0]](key[1]), plot_template(new_templates[key], title=to_string[key[0]](key[1]), savefig=True))\n",
        "    for key in new_templates\n",
        "]\n",
        "#\n",
        "#markdown = \"\"\n",
        "#for i in range(0, len(ploted_images), 5):\n",
        "#    titles, imgpaths = zip(*ploted_images[i:i+5])\n",
        "#    markdown += \"| {0} |\\n\".format(\" | \".join(titles))\n",
        "#    markdown += \"|:---:|:---:|:---:|:---:|:---:|\\n\"\n",
        "#    markdown += \"| {0} |\\n\".format(\" | \".join(map(to_md, imgpaths)))\n",
        "#    markdown += \"\\n\"\n",
        "#    \n",
        "#Markdown(markdown)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MukGJhMjaPS",
        "colab_type": "text"
      },
      "source": [
        "| above | not above | below | not below | over |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_above.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_below.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over.png?raw=1) |\n",
        "\n",
        "| not over | under | not under | next_to | not next_to |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_over.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_next_to.png?raw=1) |\n",
        "\n",
        "| away_from | not away_from | near_to | not near_to | far_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/far_from.png?raw=1) |\n",
        "\n",
        "| not far_from | left_of | not left_of | right_of | not right_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/not_right_of.png?raw=1) |\n",
        "\n",
        "| above and below | either above or below | above and over | either above or over | above and under |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_below.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_below.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_over.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_over.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_under.png?raw=1) |\n",
        "\n",
        "| either above or under | above and next_to | either above or next_to | above and away_from | either above or away_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_away_from.png?raw=1) |\n",
        "\n",
        "| above and near_to | either above or near_to | above and far_from | either above or far_from | above and left_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_left_of.png?raw=1) |\n",
        "\n",
        "| either above or left_of | above and right_of | either above or right_of | below and over | either below or over |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/above_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_above_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_over.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_over.png?raw=1) |\n",
        "\n",
        "| below and under | either below or under | below and next_to | either below or next_to | below and away_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_away_from.png?raw=1) |\n",
        "\n",
        "| either below or away_from | below and near_to | either below or near_to | below and far_from | either below or far_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_far_from.png?raw=1) |\n",
        "\n",
        "| below and left_of | either below or left_of | below and right_of | either below or right_of | over and under |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/below_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_below_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_under.png?raw=1) |\n",
        "\n",
        "| either over or under | over and next_to | either over or next_to | over and away_from | either over or away_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_under.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_away_from.png?raw=1) |\n",
        "\n",
        "| over and near_to | either over or near_to | over and far_from | either over or far_from | over and left_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_left_of.png?raw=1) |\n",
        "\n",
        "| either over or left_of | over and right_of | either over or right_of | under and next_to | either under or next_to |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/over_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_over_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_next_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_next_to.png?raw=1) |\n",
        "\n",
        "| under and away_from | either under or away_from | under and near_to | either under or near_to | under and far_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_far_from.png?raw=1) |\n",
        "\n",
        "| either under or far_from | under and left_of | either under or left_of | under and right_of | either under or right_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/under_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_under_or_right_of.png?raw=1) |\n",
        "\n",
        "| next_to and away_from | either next_to or away_from | next_to and near_to | either next_to or near_to | next_to and far_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to_and_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_next_to_or_away_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_next_to_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to_and_far_from.png?raw=1) |\n",
        "\n",
        "| either next_to or far_from | next_to and left_of | either next_to or left_of | next_to and right_of | either next_to or right_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_next_to_or_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to_and_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_next_to_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/next_to_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_next_to_or_right_of.png?raw=1) |\n",
        "\n",
        "| away_from and near_to | either away_from or near_to | away_from and far_from | either away_from or far_from | away_from and left_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/away_from_and_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_away_from_or_near_to.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/away_from_and_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_away_from_or_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/away_from_and_left_of.png?raw=1) |\n",
        "\n",
        "| either away_from or left_of | away_from and right_of | either away_from or right_of | near_to and far_from | either near_to or far_from |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_away_from_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/away_from_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_away_from_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/near_to_and_far_from.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_near_to_or_far_from.png?raw=1) |\n",
        "\n",
        "| near_to and left_of | either near_to or left_of | near_to and right_of | either near_to or right_of | far_from and left_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/near_to_and_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_near_to_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/near_to_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_near_to_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/far_from_and_left_of.png?raw=1) |\n",
        "\n",
        "| either far_from or left_of | far_from and right_of | either far_from or right_of | left_of and right_of | either left_of or right_of |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_far_from_or_left_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/far_from_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_far_from_or_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/left_of_and_right_of.png?raw=1) | ![](https://github.com/mmehdig/apl-esslli-19-material/blob/master/2-language-models-part1/plots/either_left_of_or_right_of.png?raw=1) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__ngZaLlY4b9",
        "colab_type": "text"
      },
      "source": [
        "###  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nltp61_geOVL",
        "colab_type": "text"
      },
      "source": [
        "## Generate descriptions based on acceptability of each location\n",
        "\n",
        "The idea is that expressions must be generated with a rate based on their degree of acceptability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpjOk_IUnfmI",
        "colab_type": "text"
      },
      "source": [
        "You can change the following dictionary to replicate experiments in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gil2ZXebeOVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Some systematic experiment ideas can be found here:\n",
        "@inproceedings{ghanimifard-dobnik-2017-learning,\n",
        "    title = \"Learning to Compose Spatial Relations with Grounded Neural Language Models\",\n",
        "    author = \"Ghanimifard, Mehdi  and\n",
        "      Dobnik, Simon\",\n",
        "    booktitle = \"{IWCS} 2017 - 12th International Conference on Computational Semantics - Long papers\",\n",
        "    year = \"2017\",\n",
        "    url = \"https://www.aclweb.org/anthology/W17-6808\",\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# We use the following constrains in language generation.\n",
        "# You can change it to experiment how different sequence compositions in data effects language model:\n",
        "impoverishing_policies = {\n",
        "    # we may use these variations of describing the location of the target:\n",
        "    # add distractor words in word sequence, by introducind language_variations here:\n",
        "    \"language_variations\": [\n",
        "        \"{}\",\n",
        "        #\"it is {}\",\n",
        "        #\"it is {} the box\",\n",
        "        #\"the ball is {} the box\",\n",
        "        #\"the object is {} the box\",\n",
        "    ], \n",
        "    # categorically, remove these descriptions/compositions from generated data:\n",
        "    \"excluded_base_templates\": [\n",
        "        \"not far_from\",\n",
        "        \"not under\",\n",
        "        \"away_from\",\n",
        "        \"under\",\n",
        "    ], \n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOSDFSZeOVO",
        "colab_type": "text"
      },
      "source": [
        "### Tools to encode the strings into integetr indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XIyzt_geOVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_possible_sentences = {\n",
        "    tmp.format(to_string[key](arg))\n",
        "    for key, words in new_templates\n",
        "    for tmp in impoverishing_policies[\"language_variations\"]\n",
        "    for _words in [\n",
        "        [words, (words[1], words[0])] if type(words) != str else [words]\n",
        "    ]\n",
        "    for arg in _words\n",
        "}\n",
        "\n",
        "max_len = max(len(sent.split(\" \")) for sent in all_possible_sentences)\n",
        "vocab = {w for sent in all_possible_sentences for w in sent.split(\" \")}\n",
        "vocab = [\"<pad/>\", \"<s>\", \"</s>\", ] + list(vocab)\n",
        "\n",
        "word2ix = {w: ix for ix, w in enumerate(vocab)}\n",
        "ix2word = {ix: w for w, ix in word2ix.items()}\n",
        "\n",
        "def sent2ix(sent, max_len=max_len):\n",
        "    sent = sent.split(\" \")\n",
        "    return [word2ix['<s>']] + [word2ix[w] for w in sent] + [word2ix['</s>']] + [word2ix['<pad/>']] * (max_len - len(sent))\n",
        "\n",
        "def ixs2sent(ixs):\n",
        "    return \" \".join([ix2word[ix] for ix in ixs if ix not in [word2ix['</s>'], word2ix['<pad/>']]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyzQYr17eOVR",
        "colab_type": "text"
      },
      "source": [
        "### Generate descriptions paired with situaiton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TQz5YkqeOVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generation_magnitude = 6\n",
        "np.random.seed(31415)\n",
        "\n",
        "all_generated_sentences = set([])\n",
        "sents, situs = [], []\n",
        "\n",
        "impossible_situations = set([])\n",
        "too_broad_situations = set([])\n",
        "\n",
        "\n",
        "# for each spatial expression generate possible situation\n",
        "for key, words in new_templates:\n",
        "    # skip specific descriptions\n",
        "    if to_string[key](words) in impoverishing_policies[\"excluded_base_templates\"]:\n",
        "        continue\n",
        "    \n",
        "    # spatail template of this description (acceptability of locations):\n",
        "    template = new_templates[(key, words)]\n",
        "    \n",
        "    # not a useful desciption, if there is no accepable location!\n",
        "    if template.max() <= 0.25:\n",
        "        impossible_situations = impossible_situations | {to_string[key](words), to_string[key]((words[1], words[0]))}\n",
        "        continue\n",
        "        \n",
        "    # not a useful desciption, if all locations have high acceptability!\n",
        "    template[3,3] = 1\n",
        "    if template.min() >= 0.5:\n",
        "        too_broad_situations = too_broad_situations | {to_string[key](words), to_string[key]((words[1], words[0]))}\n",
        "        continue\n",
        "    template[3,3] = 0\n",
        "    \n",
        "\n",
        "    \n",
        "    # for each location generate a description\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            # encode the sitation: (place the object in [i, j] coordinate)\n",
        "            situation = generate_situaiton(i, j)\n",
        "            \n",
        "            # size of repetition based on the acceptability scores\n",
        "            repetition = int(template[i, j] * generation_magnitude)\n",
        "            \n",
        "            # repetitedly choose a random language variation to describe the situaiton:\n",
        "            tmps = np.random.choice(impoverishing_policies[\"language_variations\"], repetition)\n",
        "            \n",
        "            # pair the situation with describtions \n",
        "            these_sents = [\n",
        "                tmp.format(to_string[key](_words))\n",
        "                for tmp in tmps\n",
        "                for _words in [\n",
        "                    sorted(words, key=lambda *args: np.random.random()) if type(words) != str else words\n",
        "                ] # random \"left_of and above\", \"above and left_of\"\n",
        "            ]\n",
        "            \n",
        "            all_generated_sentences = all_generated_sentences | set(these_sents)\n",
        "            sents += [sent2ix(sent) for sent in these_sents]\n",
        "            situs += [situation for _ in these_sents]\n",
        "    \n",
        "    \n",
        "        \n",
        "sents = np.array(sents)\n",
        "situs = np.array(situs)\n",
        "indices = np.arange(sents.shape[0])\n",
        "np.random.shuffle(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu9EP_D4eOVU",
        "colab_type": "text"
      },
      "source": [
        "There are some expressions with impossible situations: `right_of and left_of` \n",
        "\n",
        "There are some expressions that they are two in any possible situation: `either near_to or far_from\t`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMgblplReOVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_templates = {\n",
        "    to_string[key[0]](arg): new_templates[key]\n",
        "    for key in new_templates\n",
        "    for args in [[key[1]] if type(key[1]) == str else [key[1], (key[1][1], key[1][0])]]\n",
        "    for arg in args\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3CN9bjieOVX",
        "colab_type": "text"
      },
      "source": [
        "## Train Conditional Langauge Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDf5wmpyeOVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_point = int(len(indices)*0.1)\n",
        "X_valid_indices = indices[:split_point]\n",
        "X_train_indices = indices[split_point:]\n",
        "\n",
        "X_valid = [sents[X_valid_indices][:,:-1], situs[X_valid_indices].reshape([len(X_valid_indices), 7*7, 1])]\n",
        "X_train = [sents[X_train_indices][:,:-1], situs[X_train_indices].reshape([len(X_train_indices), 7*7, 1])]\n",
        "\n",
        "Y_valid = sents[X_valid_indices][:,1:]\n",
        "Y_train = sents[X_train_indices][:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Kz879seOVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    # dimensionalities:\n",
        "    emb_size = 16\n",
        "    regions_size = 7 * 7\n",
        "    visual_feature_size = 1\n",
        "\n",
        "    ### simple decoder model\n",
        "    ## inputs\n",
        "    # visual features\n",
        "    visual_features  = Input(shape=[regions_size, visual_feature_size]) \n",
        "    c = Flatten()(visual_features) \n",
        "\n",
        "    # word embeddings\n",
        "    delayed_sentence = Input(shape=[max_len+1,]) # <s> w_1 w_2 w_3 ... w_T </s> <pad/> ...\n",
        "    e_t  = Embedding(len(ix2word), emb_size)(Masking()(delayed_sentence))\n",
        "    e_t  = Dropout(0.3)(e_t)\n",
        "    \n",
        "    # fusing two modalities\n",
        "    # repeat the image vector (x[1]) and concatenate it with embeddings x[0]\n",
        "    def feature_fusion(x, max_len=max_len):\n",
        "        _e = x[0]\n",
        "        _c = K.expand_dims(x[1], 1)\n",
        "        _c = K.repeat_elements(_c, max_len+1, 1)\n",
        "        return K.concatenate([_e, _c], 2)\n",
        "    # use the function as a keras-lambda layer:\n",
        "    ec_t = Lambda(feature_fusion)([e_t, c])\n",
        "    \n",
        "    # LSTM-language model (compose sequences here)\n",
        "    h_t  = LSTM(emb_size, dropout=0.1, return_sequences=True)(ec_t)\n",
        "    \n",
        "    ## (Optional) you can fusing language model vectors with visual features again!\n",
        "    #hc_t = Lambda(feature_fusion)([h_t, c])\n",
        "    #hc_t  = Dropout(0.25)(hc_t)\n",
        "    \n",
        "    # Final layer\n",
        "    # predicts the words in corrected time sequece: w_1 w_2 ... w_T </s> <pad/> <pad/> ... \n",
        "    out  = TimeDistributed(Dense(len(ix2word), activation='softmax'))(h_t)\n",
        "    \n",
        "    # compile input-outputs as a model:\n",
        "    model = Model([delayed_sentence, visual_features], out)\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R3IvaGgfeOVf",
        "colab_type": "code",
        "outputId": "9ff96cee-55a9-4f72-b8af-05c9491b8b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.fit(x=X_train, y=Y_train, validation_data=(X_valid, Y_valid), epochs=512, batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masking_2 (Masking)             (None, 5)            0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 5, 16)        272         masking_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 49, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 5, 16)        0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 49)           0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 5, 65)        0           dropout_2[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 5, 16)        5248        lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 5, 17)        289         lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,809\n",
            "Trainable params: 5,809\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 9153 samples, validate on 1017 samples\n",
            "Epoch 1/512\n",
            "9153/9153 [==============================] - 2s 170us/sample - loss: 2.8244 - val_loss: 2.8140\n",
            "Epoch 2/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 2.8057 - val_loss: 2.7936\n",
            "Epoch 3/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.7834 - val_loss: 2.7679\n",
            "Epoch 4/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 2.7541 - val_loss: 2.7333\n",
            "Epoch 5/512\n",
            "9153/9153 [==============================] - 0s 42us/sample - loss: 2.7143 - val_loss: 2.6851\n",
            "Epoch 6/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.6592 - val_loss: 2.6185\n",
            "Epoch 7/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.5848 - val_loss: 2.5346\n",
            "Epoch 8/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.4999 - val_loss: 2.4538\n",
            "Epoch 9/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 2.4316 - val_loss: 2.4031\n",
            "Epoch 10/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 2.3913 - val_loss: 2.3695\n",
            "Epoch 11/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.3588 - val_loss: 2.3364\n",
            "Epoch 12/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 2.3279 - val_loss: 2.3038\n",
            "Epoch 13/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 2.2964 - val_loss: 2.2705\n",
            "Epoch 14/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.2625 - val_loss: 2.2338\n",
            "Epoch 15/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 2.2254 - val_loss: 2.1926\n",
            "Epoch 16/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.1834 - val_loss: 2.1454\n",
            "Epoch 17/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 2.1353 - val_loss: 2.0922\n",
            "Epoch 18/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 2.0839 - val_loss: 2.0340\n",
            "Epoch 19/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 2.0283 - val_loss: 1.9729\n",
            "Epoch 20/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.9701 - val_loss: 1.9108\n",
            "Epoch 21/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.9114 - val_loss: 1.8491\n",
            "Epoch 22/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.8548 - val_loss: 1.7885\n",
            "Epoch 23/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.7987 - val_loss: 1.7293\n",
            "Epoch 24/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.7425 - val_loss: 1.6725\n",
            "Epoch 25/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.6915 - val_loss: 1.6193\n",
            "Epoch 26/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.6418 - val_loss: 1.5708\n",
            "Epoch 27/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.5965 - val_loss: 1.5277\n",
            "Epoch 28/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.5557 - val_loss: 1.4896\n",
            "Epoch 29/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.5184 - val_loss: 1.4555\n",
            "Epoch 30/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.4866 - val_loss: 1.4249\n",
            "Epoch 31/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.4549 - val_loss: 1.3967\n",
            "Epoch 32/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.4288 - val_loss: 1.3709\n",
            "Epoch 33/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.4020 - val_loss: 1.3473\n",
            "Epoch 34/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 1.3780 - val_loss: 1.3251\n",
            "Epoch 35/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.3566 - val_loss: 1.3046\n",
            "Epoch 36/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.3350 - val_loss: 1.2852\n",
            "Epoch 37/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.3142 - val_loss: 1.2669\n",
            "Epoch 38/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.2972 - val_loss: 1.2499\n",
            "Epoch 39/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.2796 - val_loss: 1.2341\n",
            "Epoch 40/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.2641 - val_loss: 1.2194\n",
            "Epoch 41/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.2477 - val_loss: 1.2057\n",
            "Epoch 42/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.2335 - val_loss: 1.1929\n",
            "Epoch 43/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.2216 - val_loss: 1.1811\n",
            "Epoch 44/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.2087 - val_loss: 1.1702\n",
            "Epoch 45/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 1.1973 - val_loss: 1.1601\n",
            "Epoch 46/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1873 - val_loss: 1.1507\n",
            "Epoch 47/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1771 - val_loss: 1.1421\n",
            "Epoch 48/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1673 - val_loss: 1.1341\n",
            "Epoch 49/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.1599 - val_loss: 1.1267\n",
            "Epoch 50/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.1513 - val_loss: 1.1200\n",
            "Epoch 51/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1437 - val_loss: 1.1137\n",
            "Epoch 52/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1378 - val_loss: 1.1079\n",
            "Epoch 53/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.1315 - val_loss: 1.1025\n",
            "Epoch 54/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.1248 - val_loss: 1.0975\n",
            "Epoch 55/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1202 - val_loss: 1.0929\n",
            "Epoch 56/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 1.1149 - val_loss: 1.0887\n",
            "Epoch 57/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1099 - val_loss: 1.0847\n",
            "Epoch 58/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.1055 - val_loss: 1.0812\n",
            "Epoch 59/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.1015 - val_loss: 1.0777\n",
            "Epoch 60/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0973 - val_loss: 1.0746\n",
            "Epoch 61/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0942 - val_loss: 1.0716\n",
            "Epoch 62/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0909 - val_loss: 1.0690\n",
            "Epoch 63/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0879 - val_loss: 1.0664\n",
            "Epoch 64/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0842 - val_loss: 1.0640\n",
            "Epoch 65/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0808 - val_loss: 1.0619\n",
            "Epoch 66/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0789 - val_loss: 1.0598\n",
            "Epoch 67/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0762 - val_loss: 1.0580\n",
            "Epoch 68/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0752 - val_loss: 1.0562\n",
            "Epoch 69/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0725 - val_loss: 1.0545\n",
            "Epoch 70/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0693 - val_loss: 1.0529\n",
            "Epoch 71/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0678 - val_loss: 1.0514\n",
            "Epoch 72/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0663 - val_loss: 1.0500\n",
            "Epoch 73/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 1.0655 - val_loss: 1.0487\n",
            "Epoch 74/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0629 - val_loss: 1.0474\n",
            "Epoch 75/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0613 - val_loss: 1.0463\n",
            "Epoch 76/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0595 - val_loss: 1.0452\n",
            "Epoch 77/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0578 - val_loss: 1.0441\n",
            "Epoch 78/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0571 - val_loss: 1.0431\n",
            "Epoch 79/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0563 - val_loss: 1.0422\n",
            "Epoch 80/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0540 - val_loss: 1.0412\n",
            "Epoch 81/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0530 - val_loss: 1.0403\n",
            "Epoch 82/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0519 - val_loss: 1.0395\n",
            "Epoch 83/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0515 - val_loss: 1.0387\n",
            "Epoch 84/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0496 - val_loss: 1.0379\n",
            "Epoch 85/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0485 - val_loss: 1.0372\n",
            "Epoch 86/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0474 - val_loss: 1.0366\n",
            "Epoch 87/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0465 - val_loss: 1.0358\n",
            "Epoch 88/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0463 - val_loss: 1.0351\n",
            "Epoch 89/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0453 - val_loss: 1.0344\n",
            "Epoch 90/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0438 - val_loss: 1.0339\n",
            "Epoch 91/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0434 - val_loss: 1.0333\n",
            "Epoch 92/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0423 - val_loss: 1.0327\n",
            "Epoch 93/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0419 - val_loss: 1.0323\n",
            "Epoch 94/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0410 - val_loss: 1.0317\n",
            "Epoch 95/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0408 - val_loss: 1.0311\n",
            "Epoch 96/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0402 - val_loss: 1.0306\n",
            "Epoch 97/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0392 - val_loss: 1.0302\n",
            "Epoch 98/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0382 - val_loss: 1.0296\n",
            "Epoch 99/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0379 - val_loss: 1.0291\n",
            "Epoch 100/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0373 - val_loss: 1.0287\n",
            "Epoch 101/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0366 - val_loss: 1.0283\n",
            "Epoch 102/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0364 - val_loss: 1.0279\n",
            "Epoch 103/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0358 - val_loss: 1.0274\n",
            "Epoch 104/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0346 - val_loss: 1.0271\n",
            "Epoch 105/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0347 - val_loss: 1.0266\n",
            "Epoch 106/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0338 - val_loss: 1.0263\n",
            "Epoch 107/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0333 - val_loss: 1.0260\n",
            "Epoch 108/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0328 - val_loss: 1.0256\n",
            "Epoch 109/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0320 - val_loss: 1.0253\n",
            "Epoch 110/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0314 - val_loss: 1.0249\n",
            "Epoch 111/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0309 - val_loss: 1.0245\n",
            "Epoch 112/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0310 - val_loss: 1.0240\n",
            "Epoch 113/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0304 - val_loss: 1.0236\n",
            "Epoch 114/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0294 - val_loss: 1.0235\n",
            "Epoch 115/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0293 - val_loss: 1.0233\n",
            "Epoch 116/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0293 - val_loss: 1.0229\n",
            "Epoch 117/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0285 - val_loss: 1.0224\n",
            "Epoch 118/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0277 - val_loss: 1.0220\n",
            "Epoch 119/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0276 - val_loss: 1.0218\n",
            "Epoch 120/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0272 - val_loss: 1.0215\n",
            "Epoch 121/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0270 - val_loss: 1.0213\n",
            "Epoch 122/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0262 - val_loss: 1.0209\n",
            "Epoch 123/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0260 - val_loss: 1.0205\n",
            "Epoch 124/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0251 - val_loss: 1.0202\n",
            "Epoch 125/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0252 - val_loss: 1.0200\n",
            "Epoch 126/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 1.0247 - val_loss: 1.0198\n",
            "Epoch 127/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0244 - val_loss: 1.0193\n",
            "Epoch 128/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0240 - val_loss: 1.0191\n",
            "Epoch 129/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0231 - val_loss: 1.0189\n",
            "Epoch 130/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0230 - val_loss: 1.0186\n",
            "Epoch 131/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0228 - val_loss: 1.0184\n",
            "Epoch 132/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0230 - val_loss: 1.0180\n",
            "Epoch 133/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0224 - val_loss: 1.0179\n",
            "Epoch 134/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0222 - val_loss: 1.0178\n",
            "Epoch 135/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0207 - val_loss: 1.0174\n",
            "Epoch 136/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0213 - val_loss: 1.0171\n",
            "Epoch 137/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0209 - val_loss: 1.0168\n",
            "Epoch 138/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0204 - val_loss: 1.0167\n",
            "Epoch 139/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0201 - val_loss: 1.0165\n",
            "Epoch 140/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0196 - val_loss: 1.0161\n",
            "Epoch 141/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0188 - val_loss: 1.0160\n",
            "Epoch 142/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0188 - val_loss: 1.0158\n",
            "Epoch 143/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0185 - val_loss: 1.0154\n",
            "Epoch 144/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0180 - val_loss: 1.0152\n",
            "Epoch 145/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0180 - val_loss: 1.0150\n",
            "Epoch 146/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0181 - val_loss: 1.0148\n",
            "Epoch 147/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0176 - val_loss: 1.0145\n",
            "Epoch 148/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0169 - val_loss: 1.0143\n",
            "Epoch 149/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0166 - val_loss: 1.0141\n",
            "Epoch 150/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0166 - val_loss: 1.0141\n",
            "Epoch 151/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0159 - val_loss: 1.0137\n",
            "Epoch 152/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0158 - val_loss: 1.0133\n",
            "Epoch 153/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0155 - val_loss: 1.0132\n",
            "Epoch 154/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0155 - val_loss: 1.0132\n",
            "Epoch 155/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 1.0151 - val_loss: 1.0129\n",
            "Epoch 156/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0146 - val_loss: 1.0127\n",
            "Epoch 157/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0143 - val_loss: 1.0124\n",
            "Epoch 158/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0141 - val_loss: 1.0123\n",
            "Epoch 159/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0142 - val_loss: 1.0121\n",
            "Epoch 160/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0148 - val_loss: 1.0118\n",
            "Epoch 161/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0135 - val_loss: 1.0116\n",
            "Epoch 162/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0135 - val_loss: 1.0115\n",
            "Epoch 163/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0130 - val_loss: 1.0113\n",
            "Epoch 164/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0130 - val_loss: 1.0110\n",
            "Epoch 165/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0127 - val_loss: 1.0109\n",
            "Epoch 166/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0120 - val_loss: 1.0107\n",
            "Epoch 167/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0121 - val_loss: 1.0105\n",
            "Epoch 168/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0121 - val_loss: 1.0103\n",
            "Epoch 169/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0114 - val_loss: 1.0102\n",
            "Epoch 170/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0111 - val_loss: 1.0101\n",
            "Epoch 171/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0113 - val_loss: 1.0097\n",
            "Epoch 172/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0108 - val_loss: 1.0095\n",
            "Epoch 173/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0102 - val_loss: 1.0095\n",
            "Epoch 174/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0101 - val_loss: 1.0092\n",
            "Epoch 175/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0100 - val_loss: 1.0092\n",
            "Epoch 176/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0100 - val_loss: 1.0090\n",
            "Epoch 177/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 1.0099 - val_loss: 1.0088\n",
            "Epoch 178/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0091 - val_loss: 1.0086\n",
            "Epoch 179/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0090 - val_loss: 1.0084\n",
            "Epoch 180/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0082 - val_loss: 1.0083\n",
            "Epoch 181/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0090 - val_loss: 1.0082\n",
            "Epoch 182/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0089 - val_loss: 1.0079\n",
            "Epoch 183/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0081 - val_loss: 1.0078\n",
            "Epoch 184/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0073 - val_loss: 1.0076\n",
            "Epoch 185/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0080 - val_loss: 1.0074\n",
            "Epoch 186/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0065 - val_loss: 1.0074\n",
            "Epoch 187/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0079 - val_loss: 1.0071\n",
            "Epoch 188/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0073 - val_loss: 1.0069\n",
            "Epoch 189/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0069 - val_loss: 1.0068\n",
            "Epoch 190/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0061 - val_loss: 1.0065\n",
            "Epoch 191/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0062 - val_loss: 1.0064\n",
            "Epoch 192/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0064 - val_loss: 1.0063\n",
            "Epoch 193/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0061 - val_loss: 1.0062\n",
            "Epoch 194/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0053 - val_loss: 1.0059\n",
            "Epoch 195/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0057 - val_loss: 1.0058\n",
            "Epoch 196/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0048 - val_loss: 1.0055\n",
            "Epoch 197/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0044 - val_loss: 1.0054\n",
            "Epoch 198/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0046 - val_loss: 1.0053\n",
            "Epoch 199/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0047 - val_loss: 1.0050\n",
            "Epoch 200/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0045 - val_loss: 1.0048\n",
            "Epoch 201/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0043 - val_loss: 1.0047\n",
            "Epoch 202/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0045 - val_loss: 1.0044\n",
            "Epoch 203/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0036 - val_loss: 1.0043\n",
            "Epoch 204/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0035 - val_loss: 1.0043\n",
            "Epoch 205/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0041 - val_loss: 1.0040\n",
            "Epoch 206/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0034 - val_loss: 1.0039\n",
            "Epoch 207/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0025 - val_loss: 1.0036\n",
            "Epoch 208/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0030 - val_loss: 1.0035\n",
            "Epoch 209/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0020 - val_loss: 1.0033\n",
            "Epoch 210/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 1.0016 - val_loss: 1.0032\n",
            "Epoch 211/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0019 - val_loss: 1.0031\n",
            "Epoch 212/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0019 - val_loss: 1.0028\n",
            "Epoch 213/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0019 - val_loss: 1.0026\n",
            "Epoch 214/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0012 - val_loss: 1.0026\n",
            "Epoch 215/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0011 - val_loss: 1.0023\n",
            "Epoch 216/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0003 - val_loss: 1.0020\n",
            "Epoch 217/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 1.0012 - val_loss: 1.0018\n",
            "Epoch 218/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 1.0004 - val_loss: 1.0017\n",
            "Epoch 219/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9995 - val_loss: 1.0015\n",
            "Epoch 220/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 1.0001 - val_loss: 1.0013\n",
            "Epoch 221/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9991 - val_loss: 1.0014\n",
            "Epoch 222/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9999 - val_loss: 1.0009\n",
            "Epoch 223/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9995 - val_loss: 1.0008\n",
            "Epoch 224/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9993 - val_loss: 1.0006\n",
            "Epoch 225/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9990 - val_loss: 1.0004\n",
            "Epoch 226/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9993 - val_loss: 1.0002\n",
            "Epoch 227/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9987 - val_loss: 1.0001\n",
            "Epoch 228/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9980 - val_loss: 0.9999\n",
            "Epoch 229/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9981 - val_loss: 0.9999\n",
            "Epoch 230/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9986 - val_loss: 0.9998\n",
            "Epoch 231/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9976 - val_loss: 0.9995\n",
            "Epoch 232/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9976 - val_loss: 0.9991\n",
            "Epoch 233/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9980 - val_loss: 0.9990\n",
            "Epoch 234/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9970 - val_loss: 0.9989\n",
            "Epoch 235/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9972 - val_loss: 0.9987\n",
            "Epoch 236/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9967 - val_loss: 0.9983\n",
            "Epoch 237/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9966 - val_loss: 0.9983\n",
            "Epoch 238/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9957 - val_loss: 0.9979\n",
            "Epoch 239/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9964 - val_loss: 0.9978\n",
            "Epoch 240/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9959 - val_loss: 0.9976\n",
            "Epoch 241/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9948 - val_loss: 0.9975\n",
            "Epoch 242/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9947 - val_loss: 0.9972\n",
            "Epoch 243/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9949 - val_loss: 0.9970\n",
            "Epoch 244/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9944 - val_loss: 0.9968\n",
            "Epoch 245/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9937 - val_loss: 0.9966\n",
            "Epoch 246/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9945 - val_loss: 0.9963\n",
            "Epoch 247/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9941 - val_loss: 0.9961\n",
            "Epoch 248/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9942 - val_loss: 0.9961\n",
            "Epoch 249/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9935 - val_loss: 0.9959\n",
            "Epoch 250/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9932 - val_loss: 0.9957\n",
            "Epoch 251/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9936 - val_loss: 0.9954\n",
            "Epoch 252/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9928 - val_loss: 0.9950\n",
            "Epoch 253/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9928 - val_loss: 0.9950\n",
            "Epoch 254/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9929 - val_loss: 0.9947\n",
            "Epoch 255/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9922 - val_loss: 0.9945\n",
            "Epoch 256/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9916 - val_loss: 0.9944\n",
            "Epoch 257/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9926 - val_loss: 0.9940\n",
            "Epoch 258/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9916 - val_loss: 0.9939\n",
            "Epoch 259/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9916 - val_loss: 0.9938\n",
            "Epoch 260/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9916 - val_loss: 0.9937\n",
            "Epoch 261/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9913 - val_loss: 0.9934\n",
            "Epoch 262/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9904 - val_loss: 0.9932\n",
            "Epoch 263/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9903 - val_loss: 0.9930\n",
            "Epoch 264/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9908 - val_loss: 0.9931\n",
            "Epoch 265/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9906 - val_loss: 0.9929\n",
            "Epoch 266/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9896 - val_loss: 0.9924\n",
            "Epoch 267/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9896 - val_loss: 0.9922\n",
            "Epoch 268/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9900 - val_loss: 0.9922\n",
            "Epoch 269/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9889 - val_loss: 0.9920\n",
            "Epoch 270/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9886 - val_loss: 0.9918\n",
            "Epoch 271/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9883 - val_loss: 0.9914\n",
            "Epoch 272/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9896 - val_loss: 0.9915\n",
            "Epoch 273/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9877 - val_loss: 0.9914\n",
            "Epoch 274/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9882 - val_loss: 0.9914\n",
            "Epoch 275/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9877 - val_loss: 0.9908\n",
            "Epoch 276/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9871 - val_loss: 0.9907\n",
            "Epoch 277/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9871 - val_loss: 0.9906\n",
            "Epoch 278/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9876 - val_loss: 0.9904\n",
            "Epoch 279/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9873 - val_loss: 0.9903\n",
            "Epoch 280/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9865 - val_loss: 0.9902\n",
            "Epoch 281/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9876 - val_loss: 0.9901\n",
            "Epoch 282/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9856 - val_loss: 0.9899\n",
            "Epoch 283/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9858 - val_loss: 0.9897\n",
            "Epoch 284/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9863 - val_loss: 0.9896\n",
            "Epoch 285/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9847 - val_loss: 0.9896\n",
            "Epoch 286/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9855 - val_loss: 0.9894\n",
            "Epoch 287/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9858 - val_loss: 0.9892\n",
            "Epoch 288/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9853 - val_loss: 0.9890\n",
            "Epoch 289/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9844 - val_loss: 0.9889\n",
            "Epoch 290/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9853 - val_loss: 0.9887\n",
            "Epoch 291/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9845 - val_loss: 0.9886\n",
            "Epoch 292/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9840 - val_loss: 0.9885\n",
            "Epoch 293/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9834 - val_loss: 0.9884\n",
            "Epoch 294/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9837 - val_loss: 0.9883\n",
            "Epoch 295/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9845 - val_loss: 0.9881\n",
            "Epoch 296/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9839 - val_loss: 0.9879\n",
            "Epoch 297/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9832 - val_loss: 0.9878\n",
            "Epoch 298/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9832 - val_loss: 0.9877\n",
            "Epoch 299/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9832 - val_loss: 0.9876\n",
            "Epoch 300/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9823 - val_loss: 0.9876\n",
            "Epoch 301/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9829 - val_loss: 0.9875\n",
            "Epoch 302/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9826 - val_loss: 0.9873\n",
            "Epoch 303/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9818 - val_loss: 0.9874\n",
            "Epoch 304/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9814 - val_loss: 0.9872\n",
            "Epoch 305/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9819 - val_loss: 0.9870\n",
            "Epoch 306/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9825 - val_loss: 0.9870\n",
            "Epoch 307/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9819 - val_loss: 0.9869\n",
            "Epoch 308/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9816 - val_loss: 0.9867\n",
            "Epoch 309/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9821 - val_loss: 0.9865\n",
            "Epoch 310/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9808 - val_loss: 0.9865\n",
            "Epoch 311/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9810 - val_loss: 0.9864\n",
            "Epoch 312/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9813 - val_loss: 0.9863\n",
            "Epoch 313/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9809 - val_loss: 0.9861\n",
            "Epoch 314/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9809 - val_loss: 0.9860\n",
            "Epoch 315/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9800 - val_loss: 0.9860\n",
            "Epoch 316/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9800 - val_loss: 0.9859\n",
            "Epoch 317/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9797 - val_loss: 0.9859\n",
            "Epoch 318/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9807 - val_loss: 0.9857\n",
            "Epoch 319/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9794 - val_loss: 0.9857\n",
            "Epoch 320/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9799 - val_loss: 0.9857\n",
            "Epoch 321/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9786 - val_loss: 0.9856\n",
            "Epoch 322/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9798 - val_loss: 0.9855\n",
            "Epoch 323/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9794 - val_loss: 0.9853\n",
            "Epoch 324/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9787 - val_loss: 0.9853\n",
            "Epoch 325/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9798 - val_loss: 0.9850\n",
            "Epoch 326/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9786 - val_loss: 0.9849\n",
            "Epoch 327/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9775 - val_loss: 0.9847\n",
            "Epoch 328/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9783 - val_loss: 0.9846\n",
            "Epoch 329/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9782 - val_loss: 0.9846\n",
            "Epoch 330/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9773 - val_loss: 0.9846\n",
            "Epoch 331/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9782 - val_loss: 0.9845\n",
            "Epoch 332/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9777 - val_loss: 0.9843\n",
            "Epoch 333/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9780 - val_loss: 0.9842\n",
            "Epoch 334/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9782 - val_loss: 0.9842\n",
            "Epoch 335/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9777 - val_loss: 0.9842\n",
            "Epoch 336/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9758 - val_loss: 0.9842\n",
            "Epoch 337/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9775 - val_loss: 0.9840\n",
            "Epoch 338/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9770 - val_loss: 0.9840\n",
            "Epoch 339/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9765 - val_loss: 0.9839\n",
            "Epoch 340/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9765 - val_loss: 0.9838\n",
            "Epoch 341/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9777 - val_loss: 0.9838\n",
            "Epoch 342/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9764 - val_loss: 0.9837\n",
            "Epoch 343/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9762 - val_loss: 0.9836\n",
            "Epoch 344/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9762 - val_loss: 0.9836\n",
            "Epoch 345/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9762 - val_loss: 0.9831\n",
            "Epoch 346/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9760 - val_loss: 0.9831\n",
            "Epoch 347/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9758 - val_loss: 0.9831\n",
            "Epoch 348/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9752 - val_loss: 0.9830\n",
            "Epoch 349/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9755 - val_loss: 0.9833\n",
            "Epoch 350/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9753 - val_loss: 0.9831\n",
            "Epoch 351/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9749 - val_loss: 0.9827\n",
            "Epoch 352/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9746 - val_loss: 0.9828\n",
            "Epoch 353/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9747 - val_loss: 0.9827\n",
            "Epoch 354/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9751 - val_loss: 0.9827\n",
            "Epoch 355/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9748 - val_loss: 0.9827\n",
            "Epoch 356/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9746 - val_loss: 0.9828\n",
            "Epoch 357/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9737 - val_loss: 0.9824\n",
            "Epoch 358/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9743 - val_loss: 0.9822\n",
            "Epoch 359/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9741 - val_loss: 0.9824\n",
            "Epoch 360/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9739 - val_loss: 0.9826\n",
            "Epoch 361/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9748 - val_loss: 0.9825\n",
            "Epoch 362/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9740 - val_loss: 0.9822\n",
            "Epoch 363/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9751 - val_loss: 0.9823\n",
            "Epoch 364/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9728 - val_loss: 0.9821\n",
            "Epoch 365/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9731 - val_loss: 0.9820\n",
            "Epoch 366/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9740 - val_loss: 0.9821\n",
            "Epoch 367/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9731 - val_loss: 0.9821\n",
            "Epoch 368/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9730 - val_loss: 0.9819\n",
            "Epoch 369/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9722 - val_loss: 0.9819\n",
            "Epoch 370/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9725 - val_loss: 0.9815\n",
            "Epoch 371/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9728 - val_loss: 0.9816\n",
            "Epoch 372/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9714 - val_loss: 0.9817\n",
            "Epoch 373/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9725 - val_loss: 0.9817\n",
            "Epoch 374/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9727 - val_loss: 0.9815\n",
            "Epoch 375/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9719 - val_loss: 0.9813\n",
            "Epoch 376/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9716 - val_loss: 0.9815\n",
            "Epoch 377/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9725 - val_loss: 0.9812\n",
            "Epoch 378/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9717 - val_loss: 0.9814\n",
            "Epoch 379/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9723 - val_loss: 0.9814\n",
            "Epoch 380/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9729 - val_loss: 0.9816\n",
            "Epoch 381/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9720 - val_loss: 0.9813\n",
            "Epoch 382/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9716 - val_loss: 0.9812\n",
            "Epoch 383/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9710 - val_loss: 0.9810\n",
            "Epoch 384/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9716 - val_loss: 0.9810\n",
            "Epoch 385/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9713 - val_loss: 0.9808\n",
            "Epoch 386/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9716 - val_loss: 0.9806\n",
            "Epoch 387/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9720 - val_loss: 0.9809\n",
            "Epoch 388/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9711 - val_loss: 0.9809\n",
            "Epoch 389/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9707 - val_loss: 0.9806\n",
            "Epoch 390/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9706 - val_loss: 0.9806\n",
            "Epoch 391/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9711 - val_loss: 0.9806\n",
            "Epoch 392/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9709 - val_loss: 0.9806\n",
            "Epoch 393/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9703 - val_loss: 0.9806\n",
            "Epoch 394/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9706 - val_loss: 0.9804\n",
            "Epoch 395/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9700 - val_loss: 0.9803\n",
            "Epoch 396/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 0.9703 - val_loss: 0.9804\n",
            "Epoch 397/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9711 - val_loss: 0.9802\n",
            "Epoch 398/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9704 - val_loss: 0.9802\n",
            "Epoch 399/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 0.9695 - val_loss: 0.9802\n",
            "Epoch 400/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9693 - val_loss: 0.9803\n",
            "Epoch 401/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9692 - val_loss: 0.9803\n",
            "Epoch 402/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9699 - val_loss: 0.9801\n",
            "Epoch 403/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9694 - val_loss: 0.9799\n",
            "Epoch 404/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9697 - val_loss: 0.9799\n",
            "Epoch 405/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9687 - val_loss: 0.9799\n",
            "Epoch 406/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9698 - val_loss: 0.9798\n",
            "Epoch 407/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9688 - val_loss: 0.9798\n",
            "Epoch 408/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9691 - val_loss: 0.9798\n",
            "Epoch 409/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9689 - val_loss: 0.9798\n",
            "Epoch 410/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9687 - val_loss: 0.9795\n",
            "Epoch 411/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9700 - val_loss: 0.9796\n",
            "Epoch 412/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9692 - val_loss: 0.9795\n",
            "Epoch 413/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9692 - val_loss: 0.9795\n",
            "Epoch 414/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9699 - val_loss: 0.9795\n",
            "Epoch 415/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9684 - val_loss: 0.9794\n",
            "Epoch 416/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9680 - val_loss: 0.9795\n",
            "Epoch 417/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9681 - val_loss: 0.9791\n",
            "Epoch 418/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9668 - val_loss: 0.9791\n",
            "Epoch 419/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9678 - val_loss: 0.9790\n",
            "Epoch 420/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9680 - val_loss: 0.9790\n",
            "Epoch 421/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9678 - val_loss: 0.9790\n",
            "Epoch 422/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9674 - val_loss: 0.9790\n",
            "Epoch 423/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9679 - val_loss: 0.9789\n",
            "Epoch 424/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9685 - val_loss: 0.9790\n",
            "Epoch 425/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9675 - val_loss: 0.9789\n",
            "Epoch 426/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9674 - val_loss: 0.9788\n",
            "Epoch 427/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9663 - val_loss: 0.9789\n",
            "Epoch 428/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9672 - val_loss: 0.9790\n",
            "Epoch 429/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 0.9666 - val_loss: 0.9788\n",
            "Epoch 430/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9680 - val_loss: 0.9788\n",
            "Epoch 431/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9666 - val_loss: 0.9786\n",
            "Epoch 432/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9669 - val_loss: 0.9785\n",
            "Epoch 433/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9669 - val_loss: 0.9785\n",
            "Epoch 434/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9668 - val_loss: 0.9786\n",
            "Epoch 435/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9659 - val_loss: 0.9783\n",
            "Epoch 436/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9664 - val_loss: 0.9784\n",
            "Epoch 437/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9670 - val_loss: 0.9783\n",
            "Epoch 438/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9662 - val_loss: 0.9784\n",
            "Epoch 439/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9666 - val_loss: 0.9779\n",
            "Epoch 440/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9660 - val_loss: 0.9781\n",
            "Epoch 441/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9666 - val_loss: 0.9782\n",
            "Epoch 442/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9656 - val_loss: 0.9781\n",
            "Epoch 443/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9664 - val_loss: 0.9781\n",
            "Epoch 444/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9665 - val_loss: 0.9780\n",
            "Epoch 445/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9655 - val_loss: 0.9781\n",
            "Epoch 446/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9658 - val_loss: 0.9781\n",
            "Epoch 447/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9657 - val_loss: 0.9779\n",
            "Epoch 448/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9657 - val_loss: 0.9780\n",
            "Epoch 449/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9660 - val_loss: 0.9779\n",
            "Epoch 450/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9661 - val_loss: 0.9779\n",
            "Epoch 451/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9649 - val_loss: 0.9778\n",
            "Epoch 452/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9647 - val_loss: 0.9778\n",
            "Epoch 453/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9649 - val_loss: 0.9779\n",
            "Epoch 454/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9659 - val_loss: 0.9778\n",
            "Epoch 455/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9649 - val_loss: 0.9778\n",
            "Epoch 456/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9648 - val_loss: 0.9774\n",
            "Epoch 457/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9642 - val_loss: 0.9774\n",
            "Epoch 458/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9643 - val_loss: 0.9777\n",
            "Epoch 459/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9650 - val_loss: 0.9775\n",
            "Epoch 460/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9637 - val_loss: 0.9776\n",
            "Epoch 461/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9652 - val_loss: 0.9772\n",
            "Epoch 462/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9638 - val_loss: 0.9773\n",
            "Epoch 463/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9644 - val_loss: 0.9773\n",
            "Epoch 464/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9633 - val_loss: 0.9773\n",
            "Epoch 465/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9636 - val_loss: 0.9774\n",
            "Epoch 466/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9641 - val_loss: 0.9772\n",
            "Epoch 467/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9645 - val_loss: 0.9771\n",
            "Epoch 468/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9640 - val_loss: 0.9771\n",
            "Epoch 469/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9641 - val_loss: 0.9770\n",
            "Epoch 470/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9639 - val_loss: 0.9770\n",
            "Epoch 471/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9638 - val_loss: 0.9771\n",
            "Epoch 472/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9635 - val_loss: 0.9768\n",
            "Epoch 473/512\n",
            "9153/9153 [==============================] - 0s 36us/sample - loss: 0.9637 - val_loss: 0.9768\n",
            "Epoch 474/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9638 - val_loss: 0.9768\n",
            "Epoch 475/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9640 - val_loss: 0.9768\n",
            "Epoch 476/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9640 - val_loss: 0.9767\n",
            "Epoch 477/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9637 - val_loss: 0.9768\n",
            "Epoch 478/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9630 - val_loss: 0.9768\n",
            "Epoch 479/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9638 - val_loss: 0.9765\n",
            "Epoch 480/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9618 - val_loss: 0.9766\n",
            "Epoch 481/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9632 - val_loss: 0.9768\n",
            "Epoch 482/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9633 - val_loss: 0.9766\n",
            "Epoch 483/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9632 - val_loss: 0.9764\n",
            "Epoch 484/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9632 - val_loss: 0.9764\n",
            "Epoch 485/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9632 - val_loss: 0.9767\n",
            "Epoch 486/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9625 - val_loss: 0.9764\n",
            "Epoch 487/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9623 - val_loss: 0.9766\n",
            "Epoch 488/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9627 - val_loss: 0.9763\n",
            "Epoch 489/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9622 - val_loss: 0.9764\n",
            "Epoch 490/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9627 - val_loss: 0.9764\n",
            "Epoch 491/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9618 - val_loss: 0.9762\n",
            "Epoch 492/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9631 - val_loss: 0.9762\n",
            "Epoch 493/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9615 - val_loss: 0.9762\n",
            "Epoch 494/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9623 - val_loss: 0.9763\n",
            "Epoch 495/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9620 - val_loss: 0.9762\n",
            "Epoch 496/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9624 - val_loss: 0.9762\n",
            "Epoch 497/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9617 - val_loss: 0.9759\n",
            "Epoch 498/512\n",
            "9153/9153 [==============================] - 0s 41us/sample - loss: 0.9617 - val_loss: 0.9756\n",
            "Epoch 499/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9613 - val_loss: 0.9756\n",
            "Epoch 500/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9628 - val_loss: 0.9757\n",
            "Epoch 501/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9602 - val_loss: 0.9759\n",
            "Epoch 502/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9617 - val_loss: 0.9757\n",
            "Epoch 503/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9620 - val_loss: 0.9754\n",
            "Epoch 504/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9618 - val_loss: 0.9757\n",
            "Epoch 505/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9607 - val_loss: 0.9756\n",
            "Epoch 506/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9613 - val_loss: 0.9754\n",
            "Epoch 507/512\n",
            "9153/9153 [==============================] - 0s 40us/sample - loss: 0.9615 - val_loss: 0.9755\n",
            "Epoch 508/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9615 - val_loss: 0.9756\n",
            "Epoch 509/512\n",
            "9153/9153 [==============================] - 0s 38us/sample - loss: 0.9601 - val_loss: 0.9756\n",
            "Epoch 510/512\n",
            "9153/9153 [==============================] - 0s 39us/sample - loss: 0.9616 - val_loss: 0.9755\n",
            "Epoch 511/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9615 - val_loss: 0.9753\n",
            "Epoch 512/512\n",
            "9153/9153 [==============================] - 0s 37us/sample - loss: 0.9609 - val_loss: 0.9754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6011155b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0uYPV61eOVi",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbBMK-AbtMJK",
        "colab_type": "text"
      },
      "source": [
        "We use the language model to retrieve the spatial templates, by taking the likelihoods as acceptability measures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6kUdoKaeOVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unseen_descriptions = all_possible_sentences - all_generated_sentences "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8CQZB8rqeOVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unseen_sents = [sent2ix(sent) for sent in all_possible_sentences]\n",
        "all_situs = [\n",
        "    generate_situaiton(i, j)\n",
        "    for i in range(7)\n",
        "    for j in range(7)\n",
        "]\n",
        "\n",
        "restored_templates ={}\n",
        "for ixs in unseen_sents:\n",
        "    # skip if it is not a possible situaiton or it is not a valid desciption:\n",
        "    if ixs2sent(ixs[1:-1]) in (impossible_situations | too_broad_situations):\n",
        "        continue\n",
        "\n",
        "    # skip complete sentences (only take the base form) (optional)\n",
        "    if \"is\" in word2ix and word2ix[\"is\"] in ixs:\n",
        "        continue\n",
        "        \n",
        "    X_evals = [\n",
        "        np.array([ixs[:-1] for situ in all_situs]),\n",
        "        np.array([situ.reshape([7*7, 1]) for situ in all_situs]),\n",
        "    ]\n",
        "\n",
        "    Y_preds = model.predict(X_evals)\n",
        "\n",
        "    # each situation gets the likelihood of the sentence.\n",
        "    # the likelihood of the word sequence is the product of all its token probabilities:\n",
        "    # p(w_1, w_2, ..., w_T|c) = p(w_1|c) p(w_2|c, w_1) p(w_3|c, w_1 w_2) ... p(w_T|c, w_1 w_2 ... w_{T-1})\n",
        "    template_pred = np.array([\n",
        "        all_situs[i] * np.prod([pred[ix] for pred, ix in zip(y_preds, ixs[1:]) if ix not in [0, 2]])\n",
        "        for i, y_preds in enumerate(Y_preds)\n",
        "    ]).sum(0)\n",
        "    \n",
        "    template_pred = template_pred - template_pred[3,3]\n",
        "    template_pred = normalize(template_pred)\n",
        "    \n",
        "    if ixs2sent(ixs[1:]) not in all_templates:\n",
        "        print(\"Warning!\", ixs2sent(ixs[1:]), \"is not in `all_templates`\")\n",
        "    #    template_org = all_templates[ixs2sent(ixs[1:])]\n",
        "    #    plot_template(template_org, title=ixs2sent(ixs[1:])+\" (org)\")\n",
        "    \n",
        "    \n",
        "    # the likelyhoods are low but we can normalize it to be visble and actionable:\n",
        "    restored_templates[ixs2sent(ixs[1:])] = template_pred\n",
        "    #plot_template(restored_templates[ixs2sent(ixs[1:])], title=ixs2sent(ixs[1:]))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "1DbvlGDreOVs",
        "colab_type": "code",
        "outputId": "11cf82e9-8b92-48b1-a42a-50b1956a3f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results = {\n",
        "    sent: spearmanr(all_templates[sent].flatten(), restored_templates[sent].flatten()).correlation\n",
        "    for sent in restored_templates\n",
        "}\n",
        "\n",
        "average_corr = np.mean(list(results.values()))\n",
        "print(\"Average spearman rho = {0:.2f}\".format(average_corr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average spearman rho = 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX9Ho89beOVw",
        "colab_type": "code",
        "outputId": "08e3a6c8-828d-4935-a519-99cd4ad4a901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Which ones got bad results:\")\n",
        "for sent, corr in results.items():\n",
        "  # only plot those with\n",
        "  if corr < 0.4:\n",
        "    print(\"rho = {0:0.2f} {1}\".format(corr, sent))\n",
        "        \n",
        "print(\"How well model learned templates:\")\n",
        "for sent in impoverishing_policies[\"excluded_base_templates\"]:\n",
        "  plot_template(restored_templates[sent], title=sent + r\" $(\\rho={0:.2f})$\".format(corr))\n",
        "  #plot_template(all_templates[sent], title=sent+\" (orginal)\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Which ones got bad results:\n",
            "rho = 0.36 either left_of or right_of\n",
            "rho = 0.34 either over or below\n",
            "rho = 0.33 either below or above\n",
            "rho = 0.35 either above or below\n",
            "How well model learned templates:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD9CAYAAAC7rEsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf9uOhPjvRwucAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD9CAYAAAC7rEsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD9CAYAAAC7rEsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD9CAYAAAC7rEsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Lwgu_Lq4sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}